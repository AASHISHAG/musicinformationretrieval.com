{
 "metadata": {
  "name": "",
  "signature": "sha256:37b907afa0f5a76b50f919ebf9d6804feda3a709475bfd7c09ce3cbccdb32313"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Spectral Features & k-NN\n",
      "------------------------\n",
      "\n",
      "My first audio classifier: introducing K-NN!  \n",
      "\n",
      "We can now appreciate why we need additional intelligence in our systems - heuristics can't go very far in the world of complex audio signals.  We'll be using scikit.learn's implementation of the k-NN for our work here.  It proves be a straight-forward and easy to use implementation.  The steps and skills of working with one classifier will scale nicely to working with other, more complex classifiers. \n",
      "\n",
      "We're also going to be using the new features in our arsenal: cherishing those \"spectral moments\" (centroid, bandwidth, skewness, kurtosis) and also examining other spectral statistics. \n",
      " \n",
      "### Training Data\n",
      "\n",
      "First off, we want to analyze and feature extract a small collection of audio samples - storing their feature data as our \"training data\".  The commands below read all of the drum example .wav files from the MIR web site into an array, snareFileList.  \n",
      "\n",
      "First we define a function to retrieve a list of URLs from a text file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "\n",
      "def process_corpus(corpus_URL):\n",
      "    \"\"\"Read a list of files to process from the text file at corpusURL. Return a list of URLs\"\"\" \n",
      "    # Open and read each line\n",
      "    url_list_text_data = urllib2.urlopen(corpus_URL) # it's a file like object and works just like a file\n",
      "    for file_URL in url_list_text_data: # files are iterable\n",
      "        yield file_URL.rstrip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use these commands to read in a list of filenames (samples) in a directory, replacing the URL with a URL to a list of URLs (one per line) indicating where the audio / drum samples are stored."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snares_URL = \"https://ccrma.stanford.edu/workshops/mir2014/SnareCorpus.txt\"\n",
      "snare_file_list = [audio_file_URL for audio_file_URL in process_corpus(snares_URL)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kicks_URL = \"https://ccrma.stanford.edu/workshops/mir2014/KickCorpus.txt\"\n",
      "kick_file_list = [audio_file_URL for audio_file_URL in process_corpus(kicks_URL)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To access the filenames contained in the array, use the square brackets [ ] to get to the element that you want to access. For example, to access the text URL file name of the first file in the list, you would type:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "snare_URL = snare_file_list[0]\n",
      "snare_URL"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "'https://ccrma.stanford.edu/workshops/mir2014/audio/drum%20samples/snares/SNARE_01_01.WAV'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we feature extract a sample collection, we need to sequentially access audio files, segment them (or not), and feature extract them.  Loading a lot of audio files into memory is not always a feasible or desirable operation, so you will create a loop which loads an audio file, feature extracts it, and closes  the audio file.  Note that the only information that we retain in memory are the features that are extracted.\n",
      "\n",
      "Create a loop which reads in an audio file, extracts the zero crossing rate, and some spectral statistics. You can use the \"in\" operator to retrieve each audio file URL from process_corpus(), as used above. The feature information for each audio file (the \"feature vector\") should be stored as a feature array, with columns being the features and rows for each file. For example:\n",
      "\n",
      "        featuresSnare =\n",
      "\n",
      "             0.5730    1.9183    2.9713    0.0004 0.0002\n",
      "             0.4750    1.4834    2.4463    0.0004  0.0012\n",
      "             0.5900    2.2857    3.1788    0.0003  0.0041\n",
      "             0.5090    1.6622    2.6369    0.0004  0.0051\n",
      "             0.4860    1.4758    2.2085    0.0004  0.0021\n",
      "             0.6060    2.2119    3.2798    0.0004  0.0651\n",
      "             0.4990    2.0607    2.7654    0.0004  0.0721\n",
      "             0.6360    2.3153    3.0256    0.0003  0.0221\n",
      "             0.5490    2.0137    3.0342    0.0004  0.0016\n",
      "             0.5900    2.2857    3.1788    0.0003  0.0012\n",
      " \n",
      " Within your loop, here's a reminder how to read in your wav files, using an array of audio file URLs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "from essentia.standard import MonoLoader\n",
      "\n",
      "sample_rate = 44100\n",
      "urllib.urlretrieve(snare_URL, filename='/tmp/localfile.wav')\n",
      "audio = MonoLoader(filename = '/tmp/localfile.wav', sampleRate = sample_rate)()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's an example of how to feature extract the first frame from the current audio file..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " frameSize = 0.100 * sample_rate   # 100ms\n",
      " currentFrame = audio[0 : frameSize]\n",
      " # featuresSnare[i, 0] = zcr(currentFrame)\n",
      " # centroid, bandwidth, skew, kurtosis = spectralMoments(currentFrame, sample_rate, 8192)\n",
      " # featuresSnare[i, 1:4] = [centroid, bandwidth, skew, kurtosis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "4.  First, extract all of the feature data for the kick drums and store it in a feature array.  (For my example, above, I'd put it in \"featuresKick\")\n",
      "\n",
      "5.  Next, extract all of the feature data for the snares, storing them in a different array. \n",
      "Again, the kick and snare features should be separated in two different arrays!\n",
      " \n",
      "OK, no more help.  The rest is up to you!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Building Models\n",
      "\n",
      "1.  Examine the feature array for the various snare samples.  What do you notice? \n",
      "\n",
      "2.  Since the features are different scales, we will want to normalize each feature vector to a common range - storing the scaling coefficients for later use.  Many techniques exist for scaling your features.  We'll use linear scaling, which forces the features into the range -1 to 1.\n",
      "\n",
      "    For this, we'll use a scikit.learn class called [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).  MinMaxScaler fits and transforms, returning an array of scaled values, and retains coefficients which were used to scale each column into -1 to 1.  Use these functions in your code. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "import numpy as np\n",
      "\n",
      "scaler = preprocessing.MinMaxScaler(feature_range = (-1, 1))\n",
      "trainingFeatures = scaler.fit_transform(np.concatenate(featuresSnare, featuresKick))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'featuresSnare' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-a6846594904c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainingFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesSnare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesKick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'featuresSnare' is not defined"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build a k-NN model for the snare drums using scikit.learn's [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "model_snare = KNeighborsClassifier(n_neighbors = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The labels describe which \"class\" (snare or non-snare, i.e kick, in this case), the features identify. This is formed as an array of ones and twos (class labels) to correspond to the 10 snares and 10 kicks in our training sample set. For example..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = np.empty(20, np.int32)\n",
      "labels[0:9] = 1 # First 10 are the first sample type, e.g. snare\n",
      "labels[10:20] = 2 # Second 10 are the second sample type, e.g kick\n",
      "labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This k-NN model uses 5 features,  2 classes for output (the label), uses k-NN = 1, and takes in the feature data via a feature array called trainingFeatures."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_snare.fit(trainingFeatures, labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These labels indicate which sample in our feature data is a snare, vs. a non-snare.  The k-NN model uses this information to build a means of comparison and classification.  It is really important that you get these labels correct - because they are the crux of all future classifications that are made later on.  (Trust me, I've made many mistakes in this area - training models with incorrect label data.)\n",
      "\n",
      "4.  Create a script which extracts features for a single file, re-scales its feature values, and evaluates them with your kNN classifier. \n",
      "\n",
      "### Evaluating samples with your k-NN\n",
      "\n",
      "Now that the hard part is done, it's time to throw some feature data through the trained k-NN and see what it outputs. \n",
      " \n",
      "### Rescaling\n",
      "\n",
      "In evaluating a new audio file, we need to extract it's features, re-scale them to the same range as the trained feature values, and then send them through the knn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This uses the previous calculated linear scaling parameters to adjust the incoming features to the same range.  \n",
      "featuresScaled = scaler.transform(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'features' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-3e535d776ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This uses the previous calculated linear scaling parameters to adjust the incoming features to the same range.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeaturesScaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evaluating with k-NN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_output = model_snare.predict(featuresScaled)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'model_snare' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-13-5265c345102e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_snare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesScaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'model_snare' is not defined"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `model_output` provides a list of whether output is Class 1 or Class 2. If the output labels \"1\" or \"2\" aren't insightful for you, you can add an if statement to display them as strings \"snare\" and \"kick\". Now you can visually compare the output to the training labels.\n",
      " \n",
      "Once you have completed writing the function, first, test it with your training examples.  Since a k-NN model has exact representations of the training data, it will have 100% training accuracy - meaning that every training example should be predicted correctly, when fed back into the trained model. \n",
      "\n",
      "Now, test out with the examples using https://ccrma.stanford.edu/workshops/mir2014/TestKicksCorpus.txt and https://ccrma.stanford.edu/workshops/mir2014/TestSnaresCorpus.txt.  These are real-world testing samples\u2026"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}